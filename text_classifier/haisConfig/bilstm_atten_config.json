{
  "model_name": "bilstm_atten",
  "epochs": 2,
  "checkpoint_every": 100,
  "eval_every": 100,
  "learning_rate": 1e-3,
  "optimization": "adam",
  "embedding_size": 200,
  "hidden_sizes": [256],
  "sequence_length": 500,
  "batch_size": 200,
  "vocab_size": 5000,
  "num_classes": 1,
  "keep_prob": 0.5,
  "l2_reg_lambda": 0.0,
  "max_grad_norm": 5.0,
  "train_data": "data/hais/train_data.txt",
  "eval_data": "data/hais/eval_data.txt",
  "stop_word": "data/english",
  "output_path": "outputs/hais/bilstm_atten",
  "word_vectors_path": null,
  "ckpt_model_path": "ckpt_model/hais/bilstm_atten",
  "pb_model_path": "pb_model/hais/bilstm_atten"
}